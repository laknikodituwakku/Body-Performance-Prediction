{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547fc8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature-engine in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.9.1)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from pandas>=1.0.3->feature-engine) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from pandas>=1.0.3->feature-engine) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from scikit-learn>=1.0.0->feature-engine) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from scikit-learn>=1.0.0->feature-engine) (1.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature-engine) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature-engine) (1.16.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries for ML and Pre-Processing\n",
    "\n",
    "!pip install feature-engine \n",
    "!pip install imbalanced-learn\n",
    "\n",
    "from feature_engine.imputation import RandomSampleImputer\n",
    "\n",
    "\n",
    "#Importing the necessary libraries for EDA and model building\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#importing ML models from sklearn library\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "#Importing metrics functions from SK Learn\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# # Used for Downloading MNIST\n",
    "\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "\n",
    "\n",
    "\n",
    "# Used for Splitting Training and Test Sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a1d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplicates:(13393, 12)\n",
      "without duplicates:(13392, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>body_fat</th>\n",
       "      <th>gripForce</th>\n",
       "      <th>sit_and_bend_forward</th>\n",
       "      <th>sit-ups</th>\n",
       "      <th>broad_jump</th>\n",
       "      <th>BMI_val</th>\n",
       "      <th>MAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>54.7</td>\n",
       "      <td>28.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>26.23</td>\n",
       "      <td>103.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10.6</td>\n",
       "      <td>55.9</td>\n",
       "      <td>20.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>21.16</td>\n",
       "      <td>110.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>24.87</td>\n",
       "      <td>105.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>48.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.54</td>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>58.5</td>\n",
       "      <td>15.4</td>\n",
       "      <td>46.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>24.45</td>\n",
       "      <td>105.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  body_fat  gripForce  sit_and_bend_forward  sit-ups  \\\n",
       "415     25       1      20.5       54.7                  28.5     38.0   \n",
       "9229    60       1      10.6       55.9                  20.6     43.0   \n",
       "6124    63       1      22.8       33.3                  24.2     30.0   \n",
       "10788   37       1      14.2       48.9                  10.9     48.0   \n",
       "6532    46       1      16.5       58.5                  15.4     46.0   \n",
       "\n",
       "       broad_jump  BMI_val     MAP  \n",
       "415         217.0    26.23  103.33  \n",
       "9229        198.0    21.16  110.67  \n",
       "6124        191.0    24.87  105.67  \n",
       "10788       242.0    25.54  108.00  \n",
       "6532        225.0    24.45  105.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bodyPerformance.csv')\n",
    "\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "df.duplicated().sum()\n",
    "\n",
    "print(f'with duplicates:{df.shape}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'without duplicates:{df.shape}')\n",
    "\n",
    "df.rename(columns={\"height_cm\": \"height\", \"weight_kg\": \"weight\",\"body fat_%\":\"body_fat\",\n",
    "                   \"sit and bend forward_cm\":\"sit_and_bend_forward\",\"sit-ups counts\":\"sit-ups\",\n",
    "                   \"broad jump_cm\":\"broad_jump\",\"class\":\"performance\"},inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df.age = df.age.astype(int)\n",
    "\n",
    "gender = {'F':0,'M':1}\n",
    "df['gender'] =df['gender'].replace(gender)\n",
    "\n",
    "df[\"BMI_val\"]=round((df['weight']/(df['height'])/(df['height']))*10000,2)\n",
    "\n",
    "def BMI (row):\n",
    "    bmi = ((row.weight/row.height)/row.height)*10000\n",
    "    if bmi>=18.5 and bmi < 25: \n",
    "        return 0 \n",
    "    elif bmi < 18.5:\n",
    "        return 1\n",
    "    elif bmi >= 25 and bmi < 30:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "df['BMI'] = df.apply(BMI,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "Class = {'A':0, 'B':1, 'C':2, 'D':3}\n",
    "df['class'] =df['performance'].replace(Class)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df[(df[\"body_fat\"] <= 70)]\n",
    "df = df[(df[\"sit_and_bend_forward\"] <= 50)]\n",
    "df = df[(df[\"broad_jump\"] >0)]\n",
    "df = df[df['diastolic'] < df['systolic']]\n",
    "df = df[df['diastolic'] >=10]\n",
    "\n",
    "df.drop(['height','weight','performance'],axis=1, inplace=True)\n",
    "\n",
    "df[\"MAP\"]=round((((2*df['diastolic'])+(df['systolic']))/3),2)\n",
    "df.drop(['diastolic','systolic'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "y = df['class']\n",
    "df.drop(['class','BMI'], axis=1, inplace=True)\n",
    "X = df\n",
    "\n",
    "train_feature, test_feature, train_label, test_label = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_feature.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c5ed4",
   "metadata": {},
   "source": [
    "# advanced analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1854588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "=============\n",
      "Training Accuracy: 1.0000\n",
      "Training Error Rate: 0.0000\n",
      "Training F1 Score: 1.0000\n",
      "Training Confusion Matrix:\n",
      "[[2699    0    0    0]\n",
      " [   0 2667    0    0]\n",
      " [   0    0 2693    0]\n",
      " [   0    0    0 2638]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.7525\n",
      "Test Error Rate: 0.2475\n",
      "Test F1 Score: 0.7523\n",
      "Test Confusion Matrix:\n",
      "[[567  65  13   0]\n",
      " [152 417  81  26]\n",
      " [ 59 123 451  18]\n",
      " [ 11  37  77 578]]\n",
      "\n",
      "\n",
      "\n",
      "XGBoost\n",
      "=======\n",
      "Training Accuracy: 0.9424\n",
      "Training Error Rate: 0.0576\n",
      "Training F1 Score: 0.9425\n",
      "Training Confusion Matrix:\n",
      "[[2674   20    5    0]\n",
      " [ 209 2420   35    3]\n",
      " [  99  154 2440    0]\n",
      " [  15   27   49 2547]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.7600\n",
      "Test Error Rate: 0.2400\n",
      "Test F1 Score: 0.7596\n",
      "Test Confusion Matrix:\n",
      "[[576  62   7   0]\n",
      " [151 424  82  19]\n",
      " [ 65 127 441  18]\n",
      " [  8  40  63 592]]\n",
      "\n",
      "\n",
      "\n",
      "SVC\n",
      "===\n",
      "Training Accuracy: 0.6041\n",
      "Training Error Rate: 0.3959\n",
      "Training F1 Score: 0.6040\n",
      "Training Confusion Matrix:\n",
      "[[2007  662   30    0]\n",
      " [ 769 1127  703   68]\n",
      " [ 336  565 1456  336]\n",
      " [  79  196  491 1872]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.6052\n",
      "Test Error Rate: 0.3948\n",
      "Test F1 Score: 0.6058\n",
      "Test Confusion Matrix:\n",
      "[[489 150   6   0]\n",
      " [197 269 188  22]\n",
      " [ 70 151 368  62]\n",
      " [ 21  55 134 493]]\n",
      "\n",
      "\n",
      "\n",
      "LDA\n",
      "===\n",
      "Training Accuracy: 0.6130\n",
      "Training Error Rate: 0.3870\n",
      "Training F1 Score: 0.6134\n",
      "Training Confusion Matrix:\n",
      "[[1979  677   43    0]\n",
      " [ 672 1141  793   61]\n",
      " [ 249  550 1514  380]\n",
      " [  38  160  517 1923]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.6146\n",
      "Test Error Rate: 0.3854\n",
      "Test F1 Score: 0.6143\n",
      "Test Confusion Matrix:\n",
      "[[483 148  14   0]\n",
      " [189 266 204  17]\n",
      " [ 57 133 386  75]\n",
      " [  9  48 137 509]]\n",
      "\n",
      "\n",
      "\n",
      "Multiple Logistic\n",
      "=================\n",
      "Training Accuracy: 0.5921\n",
      "Training Error Rate: 0.4079\n",
      "Training F1 Score: 0.5689\n",
      "Training Confusion Matrix:\n",
      "[[2269  344   77    9]\n",
      " [ 922  776  760  209]\n",
      " [ 352  438 1112  791]\n",
      " [  57  129  275 2177]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5847\n",
      "Test Error Rate: 0.4153\n",
      "Test F1 Score: 0.5569\n",
      "Test Confusion Matrix:\n",
      "[[552  69  23   1]\n",
      " [256 167 181  72]\n",
      " [ 83  99 273 196]\n",
      " [ 17  34  80 572]]\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "===\n",
      "Training Accuracy: 0.7196\n",
      "Training Error Rate: 0.2804\n",
      "Training F1 Score: 0.7203\n",
      "Training Confusion Matrix:\n",
      "[[2415  249   31    4]\n",
      " [ 715 1718  214   20]\n",
      " [ 340  585 1700   68]\n",
      " [  84  236  453 1865]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5839\n",
      "Test Error Rate: 0.4161\n",
      "Test F1 Score: 0.5857\n",
      "Test Confusion Matrix:\n",
      "[[515 113  17   0]\n",
      " [239 314 109  14]\n",
      " [100 225 290  36]\n",
      " [ 30  72 158 443]]\n",
      "\n",
      "\n",
      "\n",
      "GausianNB\n",
      "=========\n",
      "Training Accuracy: 0.5588\n",
      "Training Error Rate: 0.4412\n",
      "Training F1 Score: 0.5490\n",
      "Training Confusion Matrix:\n",
      "[[1999  474  117  109]\n",
      " [ 860  917  568  322]\n",
      " [ 424  538 1202  529]\n",
      " [  83  199  496 1860]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5615\n",
      "Test Error Rate: 0.4385\n",
      "Test F1 Score: 0.5529\n",
      "Test Confusion Matrix:\n",
      "[[485 107  31  22]\n",
      " [217 233 149  77]\n",
      " [ 92 137 301 121]\n",
      " [ 32  57 131 483]]\n",
      "\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "==============\n",
      "Training Accuracy: 0.7668\n",
      "Training Error Rate: 0.2332\n",
      "Training F1 Score: 0.7665\n",
      "Training Confusion Matrix:\n",
      "[[2426  257    9    7]\n",
      " [ 629 1688  275   75]\n",
      " [ 266  488 1888   51]\n",
      " [  50  130  258 2200]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.7327\n",
      "Test Error Rate: 0.2673\n",
      "Test F1 Score: 0.7317\n",
      "Test Confusion Matrix:\n",
      "[[572  69   3   1]\n",
      " [162 399  88  27]\n",
      " [ 67 136 422  26]\n",
      " [ 12  43  81 567]]\n",
      "\n",
      "\n",
      "\n",
      "Ridge\n",
      "=====\n",
      "Training Accuracy: 0.5772\n",
      "Training Error Rate: 0.4228\n",
      "Training F1 Score: 0.5714\n",
      "Training Confusion Matrix:\n",
      "[[1951  618  129    1]\n",
      " [ 787  929  844  107]\n",
      " [ 318  589 1273  513]\n",
      " [  58  112  447 2021]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5921\n",
      "Test Error Rate: 0.4079\n",
      "Test F1 Score: 0.5871\n",
      "Test Confusion Matrix:\n",
      "[[486 133  25   1]\n",
      " [188 246 213  29]\n",
      " [ 71 134 327 119]\n",
      " [ 18  35 125 525]]\n",
      "\n",
      "\n",
      "\n",
      "Lasso\n",
      "=====\n",
      "Training Accuracy: 0.5773\n",
      "Training Error Rate: 0.4227\n",
      "Training F1 Score: 0.5715\n",
      "Training Confusion Matrix:\n",
      "[[1951  618  129    1]\n",
      " [ 786  929  846  106]\n",
      " [ 318  588 1274  513]\n",
      " [  58  111  448 2021]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5921\n",
      "Test Error Rate: 0.4079\n",
      "Test F1 Score: 0.5871\n",
      "Test Confusion Matrix:\n",
      "[[486 133  25   1]\n",
      " [188 246 213  29]\n",
      " [ 71 134 327 119]\n",
      " [ 18  35 125 525]]\n",
      "\n",
      "\n",
      "\n",
      "Elastic-net\n",
      "===========\n",
      "Training Accuracy: 0.5774\n",
      "Training Error Rate: 0.4226\n",
      "Training F1 Score: 0.5716\n",
      "Training Confusion Matrix:\n",
      "[[1951  618  129    1]\n",
      " [ 785  930  846  106]\n",
      " [ 318  588 1274  513]\n",
      " [  58  111  448 2021]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5921\n",
      "Test Error Rate: 0.4079\n",
      "Test F1 Score: 0.5871\n",
      "Test Confusion Matrix:\n",
      "[[486 133  25   1]\n",
      " [188 246 213  29]\n",
      " [ 71 134 327 119]\n",
      " [ 18  35 125 525]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'SVC': SVC(probability=True),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'Multiple Logistic': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'GausianNB':GaussianNB(),\n",
    "    'Gradient Boost':GradientBoostingClassifier(criterion = \"friedman_mse\"),\n",
    "    'Ridge': LogisticRegression(solver='saga', multi_class='multinomial',penalty='l2', C=1.0),\n",
    "    'Lasso': LogisticRegression(solver='saga', multi_class='multinomial',penalty='l1', C=1),\n",
    "    'Elastic-net':LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=1, solver='saga', multi_class='multinomial')\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train_feature, train_label)\n",
    "    \n",
    "    # Training set\n",
    "    train_pred = model.predict(train_feature)\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "    train_err = 1 - train_acc\n",
    "    train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "    train_cm = confusion_matrix(train_label, train_pred)\n",
    "    \n",
    "    # Test set\n",
    "    test_pred = model.predict(test_feature)\n",
    "    test_acc = accuracy_score(test_label, test_pred)\n",
    "    test_err = 1 - test_acc\n",
    "    test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "    test_cm = confusion_matrix(test_label, test_pred)\n",
    "    \n",
    "    print(name)\n",
    "    print('='*len(name))\n",
    "    print(f'Training Accuracy: {train_acc:.4f}')\n",
    "    print(f'Training Error Rate: {train_err:.4f}')\n",
    "    print(f'Training F1 Score: {train_f1:.4f}')\n",
    "    print(f'Training Confusion Matrix:\\n{train_cm}')\n",
    "    print('\\n')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test Error Rate: {test_err:.4f}')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    print(f'Test Confusion Matrix:\\n{test_cm}')\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b666c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "=======\n",
      "Training Accuracy: 0.9476\n",
      "Training Error Rate: 0.0524\n",
      "Training F1 Score: 0.9477\n",
      "Training Confusion Matrix:\n",
      "[[2668   25    6    0]\n",
      " [ 201 2439   22    5]\n",
      " [  95  122 2476    0]\n",
      " [  20   24   41 2553]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.7637\n",
      "Test Error Rate: 0.2363\n",
      "Test F1 Score: 0.7637\n",
      "Test Confusion Matrix:\n",
      "[[576  58  10   1]\n",
      " [147 433  77  19]\n",
      " [ 63 126 447  15]\n",
      " [  8  43  65 587]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(alpha=1)\n",
    "\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train_feature, train_label)\n",
    "    \n",
    "    # Training set\n",
    "    train_pred = model.predict(train_feature)\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "    train_err = 1 - train_acc\n",
    "    train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "    train_cm = confusion_matrix(train_label, train_pred)\n",
    "    \n",
    "    # Test set\n",
    "    test_pred = model.predict(test_feature)\n",
    "    test_acc = accuracy_score(test_label, test_pred)\n",
    "    test_err = 1 - test_acc\n",
    "    test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "    test_cm = confusion_matrix(test_label, test_pred)\n",
    "    \n",
    "    print(name)\n",
    "    print('='*len(name))\n",
    "    print(f'Training Accuracy: {train_acc:.4f}')\n",
    "    print(f'Training Error Rate: {train_err:.4f}')\n",
    "    print(f'Training F1 Score: {train_f1:.4f}')\n",
    "    print(f'Training Confusion Matrix:\\n{train_cm}')\n",
    "    print('\\n')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test Error Rate: {test_err:.4f}')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    print(f'Test Confusion Matrix:\\n{test_cm}')\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33830670",
   "metadata": {},
   "source": [
    "# Randomized grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02aa832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'n_estimators': 300, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20}\n",
      "Best cross-validation score:  0.740862443363787\n",
      "Training accuracy:  0.9681219033373843\n",
      "Test accuracy:  0.7454205607476635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "rf_best = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                  max_depth=grid_search.best_params_['max_depth'], \n",
    "                                  min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                                  min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
    "                                  max_features=grid_search.best_params_['max_features'])\n",
    "rf_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = rf_best.score(train_feature, train_label)\n",
    "test_acc = rf_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980da456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "# Define the model with bootstrapping\n",
    "model = RandomForestClassifier(n_estimators=200, \n",
    "                               max_features='sqrt', \n",
    "                               min_samples_leaf= 1,\n",
    "                               min_samples_split= 6,\n",
    "                               max_depth=30, \n",
    "                               random_state=42)\n",
    "\n",
    "# Train the model with bootstrapping\n",
    "n_bootstraps = 10\n",
    "bootstrapped_models = []\n",
    "for i in range(n_bootstraps):\n",
    "    X_boot, y_boot = resample(train_feature, train_label, random_state=i)\n",
    "    model_i = clone(model)\n",
    "    model_i.fit(X_boot, y_boot)\n",
    "    bootstrapped_models.append(model_i)\n",
    "\n",
    "# Make predictions by averaging the bootstrapped models\n",
    "y_pred = np.mean([model.predict(test_feature) for model in bootstrapped_models], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d63598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4804150696456951\n",
      "Train F1 score: 0.3597388995177196\n",
      "Test accuracy: 0.40523364485981306\n",
      "Test F1 score: 0.2935536401082983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Calculate accuracy and f1 score on train set\n",
    "train_pred = np.mean([model.predict(train_feature) for model in bootstrapped_models], axis=0)\n",
    "train_pred = np.round(train_pred)\n",
    "train_pred[train_pred < 0.5] = 0\n",
    "train_pred[train_pred >= 0.5] = 1\n",
    "train_acc = accuracy_score(train_label, train_pred)\n",
    "train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "\n",
    "# Calculate accuracy and f1 score on test set\n",
    "test_pred = np.mean([model.predict(test_feature) for model in bootstrapped_models], axis=0)\n",
    "test_pred = np.round(test_pred)\n",
    "test_pred[test_pred < 0.5] = 0\n",
    "test_pred[test_pred >= 0.5] = 1\n",
    "test_acc = accuracy_score(test_label, test_pred)\n",
    "test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "\n",
    "print(\"Train accuracy:\", train_acc)\n",
    "print(\"Train F1 score:\", train_f1)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb78c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "Best cross-validation score:  0.7486215499425446\n",
      "Training accuracy:  0.9987847059923343\n",
      "Test accuracy:  0.7585046728971963\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb = XGBClassifier(alpha=1)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = grid_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "xgb_best = XGBClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                         max_depth=grid_search.best_params_['max_depth'], \n",
    "                         learning_rate=grid_search.best_params_['learning_rate'],\n",
    "                         subsample=grid_search.best_params_['subsample'],\n",
    "                         colsample_bytree=grid_search.best_params_['colsample_bytree'],\n",
    "                         gamma=grid_search.best_params_['gamma'],\n",
    "                        alpha=1)\n",
    "xgb_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = xgb_best.score(train_feature, train_label)\n",
    "test_acc = xgb_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb787b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'subsample': 1.0, 'random_state': 42, 'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "Best cross-validation score:  0.7405823316861315\n",
      "Training accuracy:  0.9684958399551276\n",
      "Test accuracy:  0.7577570093457944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the Gradient Boosting model\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'random_state': [42],\n",
    "    \n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=gb, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "gb_best = GradientBoostingClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                      max_depth=grid_search.best_params_['max_depth'], \n",
    "                                      learning_rate=grid_search.best_params_['learning_rate'],\n",
    "                                     subsample= grid_search.best_params_['subsample'],\n",
    "                                     min_samples_split= grid_search.best_params_['min_samples_split'],\n",
    "                                     min_samples_leaf =grid_search.best_params_['min_samples_leaf'] ,\n",
    "                                     max_features =grid_search.best_params_['max_features'] ,\n",
    "                                     random_state =grid_search.best_params_['random_state'] \n",
    "                                    )\n",
    "gb_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = gb_best.score(train_feature, train_label)\n",
    "test_acc = gb_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c874e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'solver': 'lsqr', 'shrinkage': 'auto', 'n_components': None}\n",
      "Best cross-validation score:  0.6119476740375667\n",
      "Training accuracy:  0.6142843787977937\n",
      "Test accuracy:  0.6130841121495327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],\n",
    "    'shrinkage': [None, 'auto', 0.1, 0.5, 0.9],\n",
    "    'n_components': [None, 1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=lda, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "lda_best = LinearDiscriminantAnalysis(solver=grid_search.best_params_['solver'], \n",
    "                                      shrinkage=grid_search.best_params_['shrinkage'], \n",
    "                                      n_components=grid_search.best_params_['n_components'])\n",
    "lda_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = lda_best.score(train_feature, train_label)\n",
    "test_acc = lda_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8886d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'weights': 'distance', 'p': 1, 'n_neighbors': 7}\n",
      "Best cross-validation score:  0.5904451376964517\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.6063551401869159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=knn, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "knn_best = KNeighborsClassifier(n_neighbors=grid_search.best_params_['n_neighbors'], \n",
    "                                 weights=grid_search.best_params_['weights'], \n",
    "                                 p=grid_search.best_params_['p'])\n",
    "knn_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = knn_best.score(train_feature, train_label)\n",
    "test_acc = knn_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "gb_best.fit(train_feature, train_label)\n",
    "gb_best_predict = gb_best.predict(test_feature)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(test_label, gb_best_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(test_label, gb_best_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555f5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5975d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e688b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"LDA\": LDA(),\n",
    "}\n",
    "\n",
    "# Define parameter grids for GridSearchCV\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 4, 6]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'subsample': [0.5, 0.8, 1],\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto', 1, 0.1, 0.01],\n",
    "        'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "    },\n",
    "    \"LDA\": {\n",
    "        'solver': ['svd', 'lsqr'],\n",
    "        'tol': [1e-3, 1e-4, 1e-5],\n",
    "        'shrinkage': [None, 'auto', 0, 0.5, 1],\n",
    "        'n_components': [2, 3, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Running {name}\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # Cross-validation\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(train_feature, train_label)\n",
    "    end_time = time.time()\n",
    "    cv_time = end_time - start_time\n",
    "    \n",
    "    print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "    print(f\"Time taken for cross-validation: {cv_time:.2f} seconds\")\n",
    "    \n",
    "    # Use the best hyperparameters to fit the model on the training set\n",
    "    start_time = time.time()\n",
    "    best_model = model.set_params(**grid_search.best_params_)\n",
    "    best_model.fit(train_feature, train_label)\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    \n",
    "    # Evaluate the model on training set\n",
    "    train_pred = best_model.predict(train_feature)\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "    train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "    train_cm = confusion_matrix(train_label, train_pred)\n",
    "\n",
    "    # Evaluate the model on test set\n",
    "    start_time = time.time()\n",
    "    test_pred = best_model.predict(test_feature)\n",
    "    end_time = time.time()\n",
    "    test_time = end_time - start_time\n",
    "    test_acc = accuracy_score(test_label, test_pred)\n",
    "    test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "    test_cm = confusion_matrix(test_label, test_pred)\n",
    "    \n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
